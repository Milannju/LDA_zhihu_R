# -*- coding: utf-8 -*-
library(topicmodels)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR) 
library(readxl)
library(wordcloud)

#数据读取


text2dtm=function(text)
{
  cutter <- worker(bylines = T,stop_word = "stopwords.txt","tag")
  new_user_word(cutter, "一带一路", "n")
  comments_seg<-c()
  comments_seg<- cutter[text]
  n_seg=list()
  for(i in 1:length(comments_seg))
  {
    seg=unlist(comments_seg[i])
    seg=seg[names(seg)=="n"]
    seg=list(seg)
    n_seg[i]=seg
  }
  doc_list=strsplit(as.character(n_seg),split=" ")
 # doc_list=unlist(doc_list)
  #term.table=list()
  wordcorpus <- Corpus(VectorSource(doc_list))
  dtm <- DocumentTermMatrix(wordcorpus)
  return(dtm)
}

text2doclist=function(text)
{
  cutter <- worker(bylines = T,stop_word = "stopwords.txt","tag")
  new_user_word(cutter, "一带一路", "n")
  comments_seg<-c()
  comments_seg<- cutter[text]
  n_seg=list()
  for(i in 1:length(comments_seg))
  {
    seg=unlist(comments_seg[i])
    seg=seg[names(seg)=="n"]
    seg=list(seg)
    n_seg[i]=seg
  }
  doc_list=strsplit(as.character(n_seg),split=" ")

  return(doc_list)
}




smp<-function(cross=fold_num,n,seed)  
{  
  set.seed(seed)  
  dd=list()  
  aa0=sample(rep(1:cross,ceiling(n/cross))[1:n],n)  
  for (i in 1:cross) dd[[i]]=(1:n)[aa0==i]  
  return(dd)  
}  

selectK<-function(dtm,kv=kv_num,SEED=seed_num,cross=fold_num,sp) # change 60 to 15  
{  
  per_ctm=NULL  
  log_ctm=NULL  
  for (k in kv)  
  {  
    per=NULL  
    loglik=NULL  
    for (i in 1:3)  #only run for 3 replications#   
    {  
      cat("R is running for", "topic", k, "fold", i,  
          as.character(as.POSIXlt(Sys.time(), "Asia/Shanghai")),"\n")  
      te=sp[[i]]  #test union
      tr=setdiff(1:nrow(dtm),te)  # train union
      
#      VEM = LDA(dtm[tr, ], k = k, control = list(seed = SEED))  
#     VEM_fixed = LDA(dtm[tr,], k = k, control = list(estimate.alpha = FALSE, seed = SEED)),  
      
 #     CTM = CTM(dtm[tr,], k = k,   
#                control = list(seed = SEED, var = list(tol = 10^-4), em = list(tol = 10^-3)))    
      
       Gibbs = LDA(dtm[tr,], k = k, method = "Gibbs",  
       control = list(seed = SEED, burnin = 1000,thin = 100, iter = 1000))  
      
      per=c(per,perplexity(Gibbs,newdata=dtm[te,]))  
      loglik=c(loglik,logLik(Gibbs,newdata=dtm[te,]))  
    }  
    per_ctm=rbind(per_ctm,per)  
    log_ctm=rbind(log_ctm,loglik)  
  }  
  return(list(perplex=per_ctm,loglik=log_ctm))  
}  

## plot the perplexity  
per_plot=function(ctmK,kv_num)
{
  m_per=apply(ctmK[[1]],1,mean)  
  m_log=apply(ctmK[[2]],1,mean)  
  
  k=c(kv_num)  
  df = ctmK[[1]]  # perplexity matrix  
  matplot(k, df, type = "b", xlab = "Number of topics",   
          ylab = "Perplexity", pch=1:3,col = 1, main = '')         
  legend("bottomright", legend = paste("fold", 1:3), col=1, pch=1:3) 
}

